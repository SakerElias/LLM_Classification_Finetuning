{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f023bdb",
   "metadata": {},
   "source": [
    "# Step 2 - Embedding-based Model\n",
    "\n",
    "In this notebook we use a pre-trained sentence embedding model (MiniLM) to construct prompt+response embeddings\n",
    "and we train a classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26045052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np, re, torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6bb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "DATA = Path(\"../data\")\n",
    "TRAIN_PATH = DATA / 'train.csv'\n",
    "TEST_PATH = DATA / 'test.csv'\n",
    "OUT_DIR  = Path(\"../outputs\");  OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR  = Path(\"../artifacts\"); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15efa3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 3-class target: 0=A wins, 1=B wins, 2=Tie\n",
    "y = np.select(\n",
    "    [train_df['winner_model_a']==1, train_df['winner_model_b']==1, train_df['winner_tie']==1],\n",
    "    [0, 1, 2]\n",
    ")\n",
    "train_df['target'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693381f3",
   "metadata": {},
   "source": [
    "Text Preprocessing for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39b79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_text_from_field(text_field):\n",
    "    \"\"\"Extract text from string representation of list (e.g., '[\"text\"]' -> 'text').\"\"\"\n",
    "    if text_field is None or (isinstance(text_field, float) and pd.isna(text_field)):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        parsed = ast.literal_eval(str(text_field))\n",
    "        if isinstance(parsed, list):\n",
    "            return ' '.join(str(item) for item in parsed)\n",
    "        else:\n",
    "            return str(parsed)\n",
    "    except:\n",
    "        return str(text_field)\n",
    "\n",
    "# Apply to both train and test\n",
    "for df, df_name in [(train_df, 'train'), (test_df, 'test')]:\n",
    "    df['prompt_text'] = df['prompt'].apply(extract_text_from_field)\n",
    "    df['response_a_text'] = df['response_a'].apply(extract_text_from_field)\n",
    "    df['response_b_text'] = df['response_b'].apply(extract_text_from_field)\n",
    "    \n",
    "    # Combine prompt with responses (using [SEP] token)\n",
    "    df['text_a'] = df['prompt_text'] + \" [SEP] \" + df['response_a_text']\n",
    "    df['text_b'] = df['prompt_text'] + \" [SEP] \" + df['response_b_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fad258",
   "metadata": {},
   "source": [
    "Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf42e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elias\\OneDrive\\Bureau\\ecole\\Chung Ang\\MLP\\LLM_Classification_Finetuning\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "\n",
    "# Load pre-trained embedding model\n",
    "EMBEDDING_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabee71",
   "metadata": {},
   "source": [
    "For kaggle notebook, use code below. Since, there is no internet connection in competition env. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7842a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load from the correct nested path\n",
    "#BATCH_SIZE = 32\n",
    "#model = SentenceTransformer('/address/of/uploaded/all-minilm-l6-v2-model/', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168236fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2 on cpu\n",
      "[cache] Loaded train embeddings: (57477, 384) (57477, 384)\n",
      "[cache] Loaded test embeddings: (3, 384) (3, 384)\n",
      "Emb shapes: (57477, 768) (3, 768)\n"
     ]
    }
   ],
   "source": [
    "# --- Paths for cached embeddings\n",
    "ART_DIR = Path(\"../artifacts\"); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EMBED_A_TRAIN = ART_DIR / 'train_embeddings_a.npy'\n",
    "EMBED_B_TRAIN = ART_DIR / 'train_embeddings_b.npy'\n",
    "EMBED_A_TEST  = ART_DIR / 'test_embeddings_a.npy'\n",
    "EMBED_B_TEST  = ART_DIR / 'test_embeddings_b.npy'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Loading SentenceTransformer:\", EMBEDDING_MODEL, \"on\", device)\n",
    "st_model = SentenceTransformer(EMBEDDING_MODEL, device=device)\n",
    "st_model.max_seq_length = 512\n",
    "BATCH = 32\n",
    "\n",
    "def load_or_encode(prefix, a_path, b_path, df):\n",
    "    # Try cache\n",
    "    if a_path.exists() and b_path.exists():\n",
    "        Ea = np.load(a_path)\n",
    "        Eb = np.load(b_path)\n",
    "        if Ea.shape[0] == len(df) and Eb.shape[0] == len(df):\n",
    "            print(f\"[cache] Loaded {prefix} embeddings:\", Ea.shape, Eb.shape)\n",
    "            return Ea, Eb\n",
    "        else:\n",
    "            print(f\"[cache] Shape mismatch for {prefix} cache → recomputing.\")\n",
    "    # Compute and save\n",
    "    start = time.time()\n",
    "    print(f\"[encode] Computing {prefix} embeddings...\")\n",
    "    Ea = st_model.encode(df[\"text_a\"].tolist(), batch_size=BATCH, show_progress_bar=True, convert_to_numpy=True)\n",
    "    Eb = st_model.encode(df[\"text_b\"].tolist(), batch_size=BATCH, show_progress_bar=True, convert_to_numpy=True)\n",
    "    np.save(a_path, Ea); np.save(b_path, Eb)\n",
    "    print(f\"[encode] Saved {prefix} embeddings to {ART_DIR}  (elapsed {(time.time()-start)/60:.2f} min)\")\n",
    "    return Ea, Eb\n",
    "\n",
    "# --- Train/Test embeddings (A and B)\n",
    "train_a, train_b = load_or_encode(\"train\", EMBED_A_TRAIN, EMBED_B_TRAIN, train_df)\n",
    "test_a,  test_b  = load_or_encode(\"test\",  EMBED_A_TEST,  EMBED_B_TEST,  test_df)\n",
    "\n",
    "# --- concat A‖B\n",
    "X_emb_train = np.concatenate([train_a, train_b], axis=1)\n",
    "X_emb_test  = np.concatenate([test_a,  test_b],  axis=1)\n",
    "print(\"Emb shapes:\", X_emb_train.shape, X_emb_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cf296",
   "metadata": {},
   "source": [
    "CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8741f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: log_loss = 1.07008\n",
      "Fold 2: log_loss = 1.07554\n",
      "Fold 3: log_loss = 1.06972\n",
      "Fold 4: log_loss = 1.07088\n",
      "Fold 5: log_loss = 1.07205\n",
      "\n",
      "Cross-val log_loss → mean=1.07165, std=0.00210\n"
     ]
    }
   ],
   "source": [
    "y_emb = np.select(\n",
    "    [train_df['winner_model_a'].eq(1),\n",
    "     train_df['winner_model_b'].eq(1),\n",
    "     train_df['winner_tie'].eq(1)],\n",
    "    [0, 1, 2]\n",
    ").astype(int)\n",
    "\n",
    "# === Cross-validation on embeddings (scaled LR) ===\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_losses = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(cv.split(X_emb_train, y_emb), 1):\n",
    "    Xtr, Xva = X_emb_train[tr], X_emb_train[va]\n",
    "    ytr, yva = y_emb[tr], y_emb[va]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xtr_s = scaler.fit_transform(Xtr)\n",
    "    Xva_s = scaler.transform(Xva)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, C=1.0, random_state=42)\n",
    "    clf.fit(Xtr_s, ytr)\n",
    "    proba = clf.predict_proba(Xva_s)\n",
    "    loss = log_loss(yva, proba, labels=[0,1,2])\n",
    "    cv_losses.append(loss)\n",
    "    print(f\"Fold {fold}: log_loss = {loss:.5f}\")\n",
    "\n",
    "print(f\"\\nCross-val log_loss → mean={np.mean(cv_losses):.5f}, std={np.std(cv_losses):.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679d14a",
   "metadata": {},
   "source": [
    "Embedding model (1.072) is performing a bit worse than the lexical baseline (1.071). \n",
    "This implies lexical features capture important preference signals.\n",
    "The embedding approach might benefit from combining with lexical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721057c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\outputs\\submission_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Final fit on full training data & submission\n",
    "scaler_final = StandardScaler()\n",
    "X_emb_train_s = scaler_final.fit_transform(X_emb_train)\n",
    "X_emb_test_s  = scaler_final.transform(X_emb_test)\n",
    "\n",
    "final_lr = LogisticRegression(max_iter=2000, C=1.0, random_state=42)\n",
    "final_lr.fit(X_emb_train_s, y_emb)\n",
    "test_proba = final_lr.predict_proba(X_emb_test_s)\n",
    "\n",
    "submission_embed = pd.DataFrame({\n",
    "    'id': test_df['id'].values,\n",
    "    'winner_model_a': test_proba[:, 0],\n",
    "    'winner_model_b': test_proba[:, 1],\n",
    "    'winner_tie':     test_proba[:, 2]\n",
    "})\n",
    "submission_embed.to_csv(OUT_DIR / 'submission_embeddings.csv', index=False)\n",
    "print(\"Saved:\", OUT_DIR / 'submission_embeddings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
